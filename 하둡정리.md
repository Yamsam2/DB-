# Hadoop 하둡
***<br>
<br>
대용량 데이터의 저장과 분석이 가능한 오픈소스 프레임워크. 강력한 병렬 프로세싱 프레임워크를 구현하기 위핸 플랫폼을 제공하는 분산 데이터 스토어.  
노드를 추가하여 분산 처리가 가능한 Scale Out 방식을 사용한다.  
(Scale Out : CPU, 메모리, 하드디스크 등의 리소스를 늘리는 방식.)
 
<br>
HDFS(Hadoop Distributed File System)는 수십 테라바이트, 피타바이트 이상의 대용량 파일을 분산된 서버에 저장하고, 많은 클라이언트가 저장된 데이터를 빠르게 처리할 수 있게 설계된 파일 시스템
<br><br>
DAS(Direct-Attached Storage) : 서버에 직접 연결된 스토리지(storage)  여러 개의 하드디스크를 장착할 수 있는 외장 케이스를 이용하는 방식 (외장형 하드디스크)
<br>
NAS(Network-Attached Storage) : 일종의 파일 서버. 별도의 운영체제를 사용, 파일 시스템을 안정적으로 공유할 수 있음. 주로 이미지데이터나 첨부파일을 저장하는데 사용
<br>
SAN(Storage Area Network) : 수십에서 수백 대의 SAN 스토리지를 데이터 서버에 연결해 총괄적으로 관리해주는 네트워크. DAS의 단점을 극복하기 위해 개발됬다. 현재 SAN 기법이 시장의 절반 이상을 차지 
<br>
 
<br><br>
HDFS의 4가지 목표 
1. 장애 복구
- HDFS에 데이터를 저장하면, 복제 데이터도 함께 저장되어 데이터도 함께 저장되어 데이터 유실을 방지, 분산 서버 간에 주기적으로 상태를 체크해 빠른시간에 장애를 인지, 대처

2. 스트리밍 방식의 데이터 접근
- 랜덤 접근 방식 고려X  대신 끊김 없이 연속된 흐름으로 데이터에 접근 가능

3. 대용량 데이터 저장
- 높은 데이터 전송 대역폭과 하나의 클러스터에서 수백 대의 노드를 지원 가능, 하나의 인스턴스에서는 수백만개 이상의 파일을 지원

4. 데이터 무결성
- 데이터의 일관성. 읽기만 가능하게 해서 데이터 무결성을 유지. 2.0버젼부터는 읽기 가능

<br><br> 
하드웨어
- 마스터 서버 : 네임노드, 잡트래커, 보조네임노드를 설치하는 서버. 디스크는 2&#126;4개 정도로 구성, RAID-1을 적용. 하둡은 64GB 메모리에 1억 개의 파일을 저장가능하기때문에 이를 감안해 적정 메모리 크기를 결정. 최근에는 32GB&#126;128GB까지의 마스터 서버 메모리를 구성, CPU 코어 개수를 16&#126;24개

- 슬레이브 서버 : 테이터노드와 태스크트래커를 설치하는 서버. 디스크를 많이 설치할 수 있는 서버가 좋고, 일반적으로 4&#126;12개까지의 디스크를 설치함. 디스크 용량은 1TB&#126;3TB 정도로 구성, 디스크 종류는 7200RPM, 예산이 충분하다면 SAS디스크를 설치, CPU는 최소한 한 두 개 이상의 쿼드코어.
디스크에는 성능상 큰 문제가 발생할 수 있으므로 RAID를 구성하지 않는게 좋음 JBOD를 지원하는 장비라면 RAID와 같은 효과를 낼 수 있음
<br><br>

*하둡 에코시스템  
 Apache Hadoop 소프트웨어 라이브러리를 이루는 다양한 구성 요소. 오픈 소스 프로젝트는 물론 광범위한 보조 툴이 많음( 수집, 정제, 적재, 분석, 시각화 등)
대표적으로 HDFS, Hive, Pig, YARN, MapReduce, Spark, HBase , Oozie, Sqoop, Zookeeper 등이 있다. 



